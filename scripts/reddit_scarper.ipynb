{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key: Made a list of keywords for which I need the reddit posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=[\"husband\", \"wife\", \"girlfriend\", \"boyfriend\", \"bf\", \"gf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now traverse the Key list and fetch the reddit data. Some key parameters in url.\n",
    "#### 1) q: Keyword name\n",
    "#### 2) subreddit: Subreddit name (eg. CasualConv or Offmychest)\n",
    "#### 3) filter: Required data I need from the JSON fetched for a particular keyword.\n",
    "#### 4) size: Maximum number of post fetched.\n",
    "#### 5) after & before: Timespan of the posts fecthed.\n",
    "#### 6) sort_type: The way in which posts are sorted (eg. sort by score or date of publish)\n",
    "#### 7) sort: Sort order i.e. ascending or descending.\n",
    "\n",
    "#### Fetched the data for all keywords of \"Key\" list and appended the data all together to generate single CSV file i.e. \"dataset\".\n",
    "\n",
    "code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pushshift.io/reddit/search/submission/?q=husband&subreddit=CasualConversation&filter=id,subreddit,num_comments,score,author,title,selftext,full_link,created_utc,over_18,num_comments,allow_live_comments,no_follow,pinned&size=1000&after=1483228800&before=1546300800&sort_type=score&sort=desc\n",
      "https://api.pushshift.io/reddit/search/submission/?q=wife&subreddit=CasualConversation&filter=id,subreddit,num_comments,score,author,title,selftext,full_link,created_utc,over_18,num_comments,allow_live_comments,no_follow,pinned&size=1000&after=1483228800&before=1546300800&sort_type=score&sort=desc\n",
      "https://api.pushshift.io/reddit/search/submission/?q=girlfriend&subreddit=CasualConversation&filter=id,subreddit,num_comments,score,author,title,selftext,full_link,created_utc,over_18,num_comments,allow_live_comments,no_follow,pinned&size=1000&after=1483228800&before=1546300800&sort_type=score&sort=desc\n",
      "https://api.pushshift.io/reddit/search/submission/?q=boyfriend&subreddit=CasualConversation&filter=id,subreddit,num_comments,score,author,title,selftext,full_link,created_utc,over_18,num_comments,allow_live_comments,no_follow,pinned&size=1000&after=1483228800&before=1546300800&sort_type=score&sort=desc\n",
      "https://api.pushshift.io/reddit/search/submission/?q=bf&subreddit=CasualConversation&filter=id,subreddit,num_comments,score,author,title,selftext,full_link,created_utc,over_18,num_comments,allow_live_comments,no_follow,pinned&size=1000&after=1483228800&before=1546300800&sort_type=score&sort=desc\n",
      "https://api.pushshift.io/reddit/search/submission/?q=gf&subreddit=CasualConversation&filter=id,subreddit,num_comments,score,author,title,selftext,full_link,created_utc,over_18,num_comments,allow_live_comments,no_follow,pinned&size=1000&after=1483228800&before=1546300800&sort_type=score&sort=desc\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(key)):\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission/?q='+str(key[i])+'&subreddit=CasualConversation&filter=id,subreddit,num_comments,score,author,title,selftext,full_link,created_utc,over_18,num_comments,allow_live_comments,no_follow,pinned&size=1000&after=1483228800&before=1546300800&sort_type=score&sort=desc'\n",
    "    print(url)\n",
    "    response = requests.get(url)    \n",
    "    dict = response.json()\n",
    "    df = pd.DataFrame(dict['data'])\n",
    "    df[\"Label\"]=str(key[i])\n",
    "    dataset = pd.concat([dataset, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of posts fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10880, 13)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of number of posts for each keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wife          2000\n",
       "boyfriend     2000\n",
       "girlfriend    2000\n",
       "husband       1915\n",
       "gf            1633\n",
       "bf            1332\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('post_dataset.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now create a list of ids of all the posts fetched. This will be used to get the comments of the posts fetched above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(dataset['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10880"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now traverse through the \"ids\" list to fetch the comment data one by one.\n",
    "#### In this case also, all the commented data is for each post is appended together to form a single comment CSV file i.e. \"dataset2\"\n",
    "Code below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,10880):\n",
    "    print(i)\n",
    "    url = 'http://api.pushshift.io/reddit/comment/search/?link_id='+str(ids[i])+'&size=50&sort_type=created_utc&sort=asc&filter=author,body,created_utc,score,subreddit,no_follow&score=>-100'\n",
    "    response = requests.get(url)    \n",
    "    dict = response.json()\n",
    "    df = pd.DataFrame(dict['data'])\n",
    "    df[\"id\"]=str(ids[i])\n",
    "    dataset2 = pd.concat([dataset2, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving comment data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.to_csv('comment_dataset.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
